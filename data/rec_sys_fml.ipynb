{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c1173c4-307b-411a-a036-73cf437089fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FederatedClient:\n",
    "    def __init__(self, model, data_loader, lr=0.01):\n",
    "        self.model = model\n",
    "        self.data_loader = data_loader\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    def train(self, epochs=1):\n",
    "        \"\"\" Train the model on local data \"\"\"\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch in self.data_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                out = self.model(batch)\n",
    "                loss = self.criterion(out, batch.edge_attr.view(-1, 1))\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            print(f'Client Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        \"\"\" Evaluate the model on a given data loader \"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                out = self.model(batch)\n",
    "                loss = self.criterion(out, batch.edge_attr.view(-1, 1))\n",
    "                total_loss += loss.item()\n",
    "        return total_loss / len(data_loader)\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def get_gradients(self):\n",
    "        \"\"\" Get the gradients of the model parameters \"\"\"\n",
    "        gradients = {}\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                gradients[name] = param.grad.mean().item()\n",
    "        return gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7337548-81c1-44cb-8d20-6ff74162f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "class FederatedServer:\n",
    "    def __init__(self, model, num_clients, lr=0.01):\n",
    "        self.model = model\n",
    "        self.num_clients = num_clients\n",
    "        self.lr = lr\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    def aggregate(self, client_models):\n",
    "        \"\"\" Aggregate model parameters from clients \"\"\"\n",
    "        state_dicts = [client_model.state_dict() for client_model in client_models]\n",
    "        average_state_dict = OrderedDict()\n",
    "\n",
    "        for key in state_dicts[0].keys():\n",
    "            average_state_dict[key] = torch.mean(\n",
    "                torch.stack([state_dict[key].float() for state_dict in state_dicts]), dim=0\n",
    "            )\n",
    "        \n",
    "        self.model.load_state_dict(average_state_dict)\n",
    "    \n",
    "    def evaluate(self, test_loader):\n",
    "        \"\"\" Evaluate the global model \"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                out = self.model(batch)\n",
    "                loss = F.mse_loss(out, batch.edge_attr.view(-1, 1))\n",
    "                total_loss += loss.item()\n",
    "        return total_loss / len(test_loader)\n",
    "    \n",
    "    def get_gradients(self):\n",
    "        \"\"\" Get the gradients of the global model parameters \"\"\"\n",
    "        gradients = {}\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                gradients[name] = param.grad.mean().item()\n",
    "        return gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a897b4-7291-422d-b157-6d816c7d3295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XhaniD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "C:\\Users\\XhaniD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([3200, 1])) that is different to the input size (torch.Size([3200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client Epoch 1, Loss: 19.113727569580078\n",
      "Client 1 Validation Loss: 18.13140869140625\n",
      "Client 1 Gradients: {'conv1.bias': 1.0709213018417358, 'conv1.lin.weight': 0.00020956707885488868, 'conv2.bias': -0.046430304646492004, 'conv2.lin.weight': -0.004444539546966553, 'fc.weight': -0.3210436701774597, 'fc.bias': -8.268858909606934}\n",
      "Client Epoch 1, Loss: 18.13140869140625\n",
      "Client 2 Validation Loss: 17.025196075439453\n",
      "Client 2 Gradients: {'conv1.bias': -0.7820969223976135, 'conv1.lin.weight': -0.00015519207227043808, 'conv2.bias': -0.2402704656124115, 'conv2.lin.weight': -0.008603132329881191, 'fc.weight': -0.35288503766059875, 'fc.bias': -8.027332305908203}\n",
      "Client Epoch 1, Loss: 17.025196075439453\n",
      "Client 3 Validation Loss: 15.4755277633667\n",
      "Client 3 Gradients: {'conv1.bias': -2.2816295623779297, 'conv1.lin.weight': -0.00044579882523976266, 'conv2.bias': -0.39783018827438354, 'conv2.lin.weight': -0.03395041450858116, 'fc.weight': -0.6436702013015747, 'fc.bias': -7.743130683898926}\n",
      "Round 1 Global Validation Loss: 15.4755277633667\n",
      "Server Gradients: {'conv1.bias': -2.2816295623779297, 'conv1.lin.weight': -0.00044579882523976266, 'conv2.bias': -0.39783018827438354, 'conv2.lin.weight': -0.03395041450858116, 'fc.weight': -0.6436702013015747, 'fc.bias': -7.743130683898926}\n",
      "Round 1 completed\n",
      "Client Epoch 1, Loss: 15.4755277633667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XhaniD\\AppData\\Local\\Temp\\ipykernel_12600\\2777615108.py:89: UserWarning: Using a target size (torch.Size([3200, 1])) that is different to the input size (torch.Size([3200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(out, batch.edge_attr.view(-1, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 Validation Loss: 13.479087829589844\n",
      "Client 1 Gradients: {'conv1.bias': -2.9728012084960938, 'conv1.lin.weight': -0.0005810576840303838, 'conv2.bias': -0.5287426710128784, 'conv2.lin.weight': -0.08147692680358887, 'fc.weight': -0.9975160360336304, 'fc.bias': -7.319465637207031}\n",
      "Client Epoch 1, Loss: 13.479087829589844\n",
      "Client 2 Validation Loss: 11.068203926086426\n",
      "Client 2 Gradients: {'conv1.bias': -3.824488878250122, 'conv1.lin.weight': -0.0007477003964595497, 'conv2.bias': -0.6182824373245239, 'conv2.lin.weight': -0.13989229500293732, 'fc.weight': -1.3615922927856445, 'fc.bias': -6.718288898468018}\n",
      "Client Epoch 1, Loss: 11.068203926086426\n",
      "Client 3 Validation Loss: 8.517389297485352\n",
      "Client 3 Gradients: {'conv1.bias': -4.155227184295654, 'conv1.lin.weight': -0.0008128521149046719, 'conv2.bias': -0.6055759191513062, 'conv2.lin.weight': -0.15982277691364288, 'fc.weight': -1.6808114051818848, 'fc.bias': -5.870171546936035}\n",
      "Round 2 Global Validation Loss: 8.517389297485352\n",
      "Server Gradients: {'conv1.bias': -4.155227184295654, 'conv1.lin.weight': -0.0008128521149046719, 'conv2.bias': -0.6055759191513062, 'conv2.lin.weight': -0.15982277691364288, 'fc.weight': -1.6808114051818848, 'fc.bias': -5.870171546936035}\n",
      "Round 2 completed\n",
      "Client Epoch 1, Loss: 8.517389297485352\n",
      "Client 1 Validation Loss: 6.549339771270752\n",
      "Client 1 Gradients: {'conv1.bias': -3.826828956604004, 'conv1.lin.weight': -0.000750063278246671, 'conv2.bias': -0.5464568138122559, 'conv2.lin.weight': -0.16123919188976288, 'fc.weight': -1.6523733139038086, 'fc.bias': -4.6952009201049805}\n",
      "Client Epoch 1, Loss: 6.549339771270752\n",
      "Client 2 Validation Loss: 5.479219436645508\n",
      "Client 2 Gradients: {'conv1.bias': -2.0030412673950195, 'conv1.lin.weight': -0.0003952178230974823, 'conv2.bias': -0.4096035659313202, 'conv2.lin.weight': -0.09298817813396454, 'fc.weight': -0.9411560297012329, 'fc.bias': -3.1382060050964355}\n",
      "Client Epoch 1, Loss: 5.479219436645508\n",
      "Client 3 Validation Loss: 5.257816314697266\n",
      "Client 3 Gradients: {'conv1.bias': 0.7784373164176941, 'conv1.lin.weight': 0.00014592056686524302, 'conv2.bias': -0.22972775995731354, 'conv2.lin.weight': 0.015627549961209297, 'fc.weight': 0.06408847868442535, 'fc.bias': -1.5860319137573242}\n",
      "Round 3 Global Validation Loss: 5.257816791534424\n",
      "Server Gradients: {'conv1.bias': 0.7784373164176941, 'conv1.lin.weight': 0.00014592056686524302, 'conv2.bias': -0.22972775995731354, 'conv2.lin.weight': 0.015627549961209297, 'fc.weight': 0.06408847868442535, 'fc.bias': -1.5860319137573242}\n",
      "Round 3 completed\n",
      "Client Epoch 1, Loss: 5.257816791534424\n",
      "Client 1 Validation Loss: 4.259909629821777\n",
      "Client 1 Gradients: {'conv1.bias': -2.3332996368408203, 'conv1.lin.weight': -0.0004592282639350742, 'conv2.bias': -0.4046335518360138, 'conv2.lin.weight': -0.1214790791273117, 'fc.weight': -1.237924337387085, 'fc.bias': -2.805673360824585}\n",
      "Client Epoch 1, Loss: 4.259909629821777\n",
      "Client 2 Validation Loss: 4.043758392333984\n",
      "Client 2 Gradients: {'conv1.bias': 0.5512080192565918, 'conv1.lin.weight': 0.0001024069933919236, 'conv2.bias': -0.18441437184810638, 'conv2.lin.weight': 0.0012190467678010464, 'fc.weight': -0.07546734064817429, 'fc.bias': -1.1674418449401855}\n",
      "Client Epoch 1, Loss: 4.043758392333984\n",
      "Client 3 Validation Loss: 4.077477931976318\n",
      "Client 3 Gradients: {'conv1.bias': -2.058032512664795, 'conv1.lin.weight': -0.0004058038757648319, 'conv2.bias': -0.3447836935520172, 'conv2.lin.weight': -0.10871580243110657, 'fc.weight': -1.0330252647399902, 'fc.bias': -2.0883536338806152}\n",
      "Round 4 Global Validation Loss: 4.077477931976318\n",
      "Server Gradients: {'conv1.bias': -2.058032512664795, 'conv1.lin.weight': -0.0004058038757648319, 'conv2.bias': -0.3447836935520172, 'conv2.lin.weight': -0.10871580243110657, 'fc.weight': -1.0330252647399902, 'fc.bias': -2.0883536338806152}\n",
      "Round 4 completed\n",
      "Client Epoch 1, Loss: 4.077477931976318\n",
      "Client 1 Validation Loss: 3.6883633136749268\n",
      "Client 1 Gradients: {'conv1.bias': 3.235450506210327, 'conv1.lin.weight': 0.0006264030816964805, 'conv2.bias': 0.030844222754240036, 'conv2.lin.weight': 0.12983545660972595, 'fc.weight': 1.0737147331237793, 'fc.bias': 0.17734909057617188}\n",
      "Client Epoch 1, Loss: 3.6883633136749268\n",
      "Client 2 Validation Loss: 3.8984761238098145\n",
      "Client 2 Gradients: {'conv1.bias': -1.8127756118774414, 'conv1.lin.weight': -0.0003574084839783609, 'conv2.bias': -0.3182889521121979, 'conv2.lin.weight': -0.1011616662144661, 'fc.weight': -0.9772254228591919, 'fc.bias': -1.8526650667190552}\n",
      "Client Epoch 1, Loss: 3.8984761238098145\n",
      "Client 3 Validation Loss: 3.4597325325012207\n",
      "Client 3 Gradients: {'conv1.bias': 3.612901449203491, 'conv1.lin.weight': 0.0007005834486335516, 'conv2.bias': 0.08374472707509995, 'conv2.lin.weight': 0.14894628524780273, 'fc.weight': 1.2564067840576172, 'fc.bias': 0.4701251685619354}\n",
      "Round 5 Global Validation Loss: 3.4597325325012207\n",
      "Server Gradients: {'conv1.bias': 3.612901449203491, 'conv1.lin.weight': 0.0007005834486335516, 'conv2.bias': 0.08374472707509995, 'conv2.lin.weight': 0.14894628524780273, 'fc.weight': 1.2564067840576172, 'fc.bias': 0.4701251685619354}\n",
      "Round 5 completed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.fc = torch.nn.Linear(hidden_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        edge_pred = self.fc(torch.cat([x[edge_index[0]], x[edge_index[1]]], dim=1))\n",
    "        return edge_pred.squeeze()\n",
    "\n",
    "# Define the Federated Client class\n",
    "class FederatedClient:\n",
    "    def __init__(self, model, data_loader, lr=0.01):\n",
    "        self.model = model\n",
    "        self.data_loader = data_loader\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    def train(self, epochs=1):\n",
    "        \"\"\" Train the model on local data \"\"\"\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch in self.data_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                out = self.model(batch)\n",
    "                loss = self.criterion(out, batch.edge_attr.view(-1, 1))\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            print(f'Client Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        \"\"\" Evaluate the model on a given data loader \"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                out = self.model(batch)\n",
    "                loss = self.criterion(out, batch.edge_attr.view(-1, 1))\n",
    "                total_loss += loss.item()\n",
    "        return total_loss / len(data_loader)\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def get_gradients(self):\n",
    "        \"\"\" Get the gradients of the model parameters \"\"\"\n",
    "        gradients = {}\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                gradients[name] = param.grad.mean().item()\n",
    "        return gradients\n",
    "\n",
    "# Define the Federated Server class\n",
    "class FederatedServer:\n",
    "    def __init__(self, model, num_clients, lr=0.01):\n",
    "        self.model = model\n",
    "        self.num_clients = num_clients\n",
    "        self.lr = lr\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    def aggregate(self, client_models):\n",
    "        \"\"\" Aggregate model parameters from clients \"\"\"\n",
    "        state_dicts = [client_model.state_dict() for client_model in client_models]\n",
    "        average_state_dict = {key: torch.mean(torch.stack([state_dict[key].float() for state_dict in state_dicts]), dim=0) for key in state_dicts[0]}\n",
    "        self.model.load_state_dict(average_state_dict)\n",
    "    \n",
    "    def evaluate(self, test_loader):\n",
    "        \"\"\" Evaluate the global model \"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                out = self.model(batch)\n",
    "                loss = F.mse_loss(out, batch.edge_attr.view(-1, 1))\n",
    "                total_loss += loss.item()\n",
    "        return total_loss / len(test_loader)\n",
    "    \n",
    "    def get_gradients(self):\n",
    "        \"\"\" Get the gradients of the global model parameters \"\"\"\n",
    "        gradients = {}\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                gradients[name] = param.grad.mean().item()\n",
    "        return gradients\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_data():\n",
    "    url = \"ratings_Electronics (1).csv\"\n",
    "    df = pd.read_csv(url)\n",
    "    df.rename(columns={'AKM1MP6P0OYPR': 'userId', '0132793040': 'productId', '5.0': 'Rating', '1365811200': 'timestamp'}, inplace=True)\n",
    "    df = df.head(5000)\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    user_encoder = LabelEncoder()\n",
    "    item_encoder = LabelEncoder()\n",
    "    df['userId'] = user_encoder.fit_transform(df['userId'])\n",
    "    df['productId'] = item_encoder.fit_transform(df['productId'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_data_objects(df, split_ratio=0.2):\n",
    "    train_df, test_df = train_test_split(df, test_size=split_ratio, random_state=42)\n",
    "    train_df, val_df = train_test_split(train_df, test_size=split_ratio, random_state=42)\n",
    "\n",
    "    edge_index = torch.tensor([train_df['userId'].values, train_df['productId'].values], dtype=torch.long)\n",
    "    edge_attr = torch.tensor(train_df['Rating'].values, dtype=torch.float)\n",
    "    num_users = df['userId'].nunique()\n",
    "    num_items = df['productId'].nunique()\n",
    "    num_nodes = num_users + num_items\n",
    "    node_features = torch.eye(num_nodes)\n",
    "    data = Data(edge_index=edge_index, edge_attr=edge_attr, x=node_features)\n",
    "    \n",
    "    train_loader = DataLoader([data], batch_size=1, shuffle=True)\n",
    "    val_loader = DataLoader([data], batch_size=1, shuffle=False)\n",
    "    \n",
    "    return data, train_loader, val_loader\n",
    "\n",
    "# Initialize models and federated setup\n",
    "num_clients = 3\n",
    "df = load_data()\n",
    "client_data = [create_data_objects(df)[0] for _ in range(num_clients)]\n",
    "client_train_loaders = [create_data_objects(df)[1] for _ in range(num_clients)]\n",
    "client_val_loaders = [create_data_objects(df)[2] for _ in range(num_clients)]\n",
    "\n",
    "# Initialize the global model and server\n",
    "model = GCN(in_channels=client_data[0].x.size(1), hidden_channels=16, out_channels=1)\n",
    "server = FederatedServer(model, num_clients)\n",
    "\n",
    "# Federated learning rounds\n",
    "for round in range(5):  # Number of federated learning rounds\n",
    "    client_models = []\n",
    "    \n",
    "    # Train clients\n",
    "    for i, client_loader in enumerate(client_train_loaders):\n",
    "        client = FederatedClient(model, client_loader)\n",
    "        client.train(epochs=1)  # Train each client for 1 epoch\n",
    "        client_models.append(client.get_model())\n",
    "        \n",
    "        # Evaluate client model\n",
    "        val_loss = client.evaluate(client_val_loaders[i])\n",
    "        print(f'Client {i + 1} Validation Loss: {val_loss}')\n",
    "        \n",
    "        # Inspect gradients\n",
    "        gradients = client.get_gradients()\n",
    "        print(f'Client {i + 1} Gradients: {gradients}')\n",
    "    \n",
    "    # Aggregate client models\n",
    "    server.aggregate(client_models)\n",
    "    \n",
    "    # Evaluate global model\n",
    "    test_loader = create_data_objects(df)[2]  # Use test loader for evaluation\n",
    "    global_val_loss = server.evaluate(test_loader)\n",
    "    print(f'Round {round + 1} Global Validation Loss: {global_val_loss}')\n",
    "    \n",
    "    # Inspect server model gradients\n",
    "    server_gradients = server.get_gradients()\n",
    "    print(f'Server Gradients: {server_gradients}')\n",
    "    \n",
    "    print(f'Round {round + 1} completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547938c-e9f7-4448-8616-a7605159151d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
